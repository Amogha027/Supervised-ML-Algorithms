{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tabulate import tabulate\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, type, depth=10, features=7, criterion='gini'):\n",
    "        self.type = type\n",
    "        self.depth = depth\n",
    "        self.features = features\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def setDepth(self, depth):\n",
    "        self.depth = depth\n",
    "\n",
    "    def setFeatures(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def setCriterion(self, criterion):\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def classify(self, x_train, y_train, x_test):\n",
    "        model = DecisionTreeClassifier(criterion=self.criterion, max_depth=self.depth, max_features=self.features)\n",
    "        if self.type == 'powerset':\n",
    "            clf = LabelPowerset(classifier=model).fit(x_train, y_train)\n",
    "        else:\n",
    "            clf = MultiOutputClassifier(model).fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(vec):\n",
    "    labels = []\n",
    "    for x in vec:\n",
    "        temp = []\n",
    "        for y in x.split():\n",
    "            temp.append(y)\n",
    "        labels.append(temp)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_labels = mlb.fit_transform(labels)\n",
    "    return y_labels\n",
    "\n",
    "def preprocess_data(data):\n",
    "    names = list(data.columns)\n",
    "    names[9] = 'most_brought_item'\n",
    "    data.columns = names\n",
    "\n",
    "    # one hot encoding\n",
    "    X = data.iloc[:,0:10]\n",
    "    Y = data.iloc[:,10]\n",
    "    crt = ['gender', 'education', 'married', 'city', 'occupation', 'most_brought_item']\n",
    "    X = pd.get_dummies(X, columns=crt)\n",
    "    Y = encode_label(Y)\n",
    "    return X, Y\n",
    "\n",
    "def split_data(X, Y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def get_accuracy(actual, predicted):\n",
    "    return 1-hamming_loss(actual, predicted)\n",
    "\n",
    "def get_scores(actual, predicted):\n",
    "    fmacro = f1_score(actual, predicted, zero_division=0, average='macro')\n",
    "    fmicro = f1_score(actual, predicted, zero_division=0, average='micro')\n",
    "    accuracy = get_accuracy(actual, predicted)\n",
    "    # accuracy = accuracy_score(actual, predicted)\n",
    "    precision = precision_score(actual, predicted, zero_division=0, average='weighted')\n",
    "    recall = recall_score(actual, predicted, zero_division=0, average='weighted')\n",
    "    return [fmacro, fmicro, accuracy, precision, recall]\n",
    "\n",
    "def print_results(actual, predicted):\n",
    "    result = get_scores(actual, predicted)\n",
    "    t = PrettyTable(['Measure', 'Value'])\n",
    "    t.add_row(['F1-macro', result[0]])\n",
    "    t.add_row(['F1-micro', result[1]])\n",
    "    t.add_row(['Accuracy', result[2]])\n",
    "    t.add_row(['Precision', result[3]])\n",
    "    t.add_row(['Recall', result[4]])\n",
    "    print(t)\n",
    "    print('confusion Matrix: ',)\n",
    "    print(np.sum(multilabel_confusion_matrix(actual, predicted), axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('advertisement.csv')\n",
    "X, Y = preprocess_data(data)\n",
    "x_train, x_test, y_train, y_test = split_data(X, Y)\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [3, 5, 10, 20, 30]\n",
    "max_features = [3, 5, 7, 9, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POWERSET FORMULATION\n",
    "dTreePS = DecisionTree('powerset')\n",
    "# y_pred = dTreePS.classify(x_train, y_train, x_test)\n",
    "# print_results(y_test, y_pred)\n",
    "\n",
    "resultPS = []\n",
    "for crt in criterion:\n",
    "    for depth in max_depth:\n",
    "        for features in max_features:\n",
    "            dTreePS.setCriterion(crt)\n",
    "            dTreePS.setDepth(depth)\n",
    "            dTreePS.setFeatures(features)\n",
    "            y_pred = dTreePS.classify(x_train, y_train, x_test)\n",
    "            resultPS.append([crt, depth, features, y_pred])\n",
    "\n",
    "# Report the metrics\n",
    "topPS = []\n",
    "for vec in resultPS:\n",
    "    print('Criterion: ', vec[0])\n",
    "    print('Max depth: ', vec[1])\n",
    "    print('Max features: ', vec[2])\n",
    "    print_results(y_test, vec[3])\n",
    "    score = get_scores(y_test, vec[3])\n",
    "    topPS.append([score[2], vec[0], vec[1], vec[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIOUTPUT FORMULATION\n",
    "dTreeMO = DecisionTree('multioutput')\n",
    "# y_pred = dTreeMO.classify(x_train, y_train, x_test)\n",
    "# print_results(y_test, y_pred)\n",
    "\n",
    "resultMO = []\n",
    "for crt in criterion:\n",
    "    for depth in max_depth:\n",
    "        for features in max_features:\n",
    "            dTreeMO.setCriterion(crt)\n",
    "            dTreeMO.setDepth(depth)\n",
    "            dTreeMO.setFeatures(features)\n",
    "            y_pred = dTreeMO.classify(x_train, y_train, x_test)\n",
    "            resultMO.append([crt, depth, features, y_pred])\n",
    "\n",
    "# Report the metrics\n",
    "topMO = []\n",
    "for vec in resultMO:\n",
    "    print('Criterion: ', vec[0])\n",
    "    print('Max depth: ', vec[1])\n",
    "    print('Max features: ', vec[2])\n",
    "    print_results(y_test, vec[3])\n",
    "    score = get_scores(y_test, vec[3])\n",
    "    topMO.append([score[2], vec[0], vec[1], vec[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 performing set of hyperparamters according to F1 Score(macro).\n",
    "headers = ['F1-score', 'Criterion', 'Max depth', 'Max features']\n",
    "\n",
    "topPS = sorted(topPS, key=lambda x:x[0], reverse=True)[:3]\n",
    "topMO = sorted(topMO, key=lambda x:x[0], reverse=True)[:3]\n",
    "print('POWERSET FORMULATION')\n",
    "print(tabulate(topPS, headers=headers,tablefmt='grid'))\n",
    "print()\n",
    "\n",
    "print('MULTIOUTPUT FORMULATION')\n",
    "print(tabulate(topMO, headers=headers,tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Fold validation metrics\n",
    "K = 8\n",
    "kf = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# powerset formulation\n",
    "dTreePS.setCriterion(topPS[0][1])\n",
    "dTreePS.setDepth(topPS[0][2])\n",
    "dTreePS.setFeatures(topPS[0][3])\n",
    "\n",
    "# multioutput formulation\n",
    "dTreeMO.setCriterion(topMO[0][1])\n",
    "dTreeMO.setDepth(topMO[0][2])\n",
    "dTreeMO.setFeatures(topMO[0][3])\n",
    "\n",
    "X = x_train\n",
    "Y = y_train\n",
    "valuesPS = []\n",
    "valuesMO = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train, x_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    valuesPS.append(get_scores(y_test, dTreePS.classify(x_train, y_train, x_test))[2])\n",
    "    valuesMO.append(get_scores(y_test, dTreeMO.classify(x_train, y_train, x_test))[2])\n",
    "\n",
    "print('Average Accuracy after k Fold validation: ')\n",
    "print('Powerset formulation: ', round(sum(valuesPS) / len(valuesPS), 2))\n",
    "print('Multioutput formulation: ', round(sum(valuesMO) / len(valuesMO), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
